"use strict";(self.webpackChunkcode_groundlight_ai=self.webpackChunkcode_groundlight_ai||[]).push([[4713],{2674:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>r,default:()=>l,frontMatter:()=>s,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"guide/edge","title":"Processing Images on the Edge","description":"If your account includes access to edge models, you can download and install them on your edge devices. This allows you to run Groundlight\'s ML models locally on your edge devices, reducing latency and increasing throughput. Additionally, inference requests handled on the edge are not counted towards your account\'s usage limits.","source":"@site/docs/guide/8-edge.md","sourceDirName":"guide","slug":"/guide/edge","permalink":"/python-sdk/docs/guide/edge","draft":false,"unlisted":false,"editUrl":"https://github.com/groundlight/python-sdk/tree/main/docs/docs/guide/8-edge.md","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Using Asynchronous Queries","permalink":"/python-sdk/docs/guide/async-queries"},"next":{"title":"Configuring Alerts","permalink":"/python-sdk/docs/guide/alerts"}}');var i=t(4848),d=t(8453);const s={},r="Processing Images on the Edge",a={},c=[{value:"How the Edge Endpoint Works",id:"how-the-edge-endpoint-works",level:2},{value:"Installing and Running the Edge Endpoint",id:"installing-and-running-the-edge-endpoint",level:2},{value:"Using the Edge Endpoint",id:"using-the-edge-endpoint",level:2},{value:"Edge Endpoint performance",id:"edge-endpoint-performance",level:2}];function h(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",img:"img",p:"p",pre:"pre",...(0,d.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"processing-images-on-the-edge",children:"Processing Images on the Edge"})}),"\n",(0,i.jsx)(n.p,{children:"If your account includes access to edge models, you can download and install them on your edge devices. This allows you to run Groundlight's ML models locally on your edge devices, reducing latency and increasing throughput. Additionally, inference requests handled on the edge are not counted towards your account's usage limits."}),"\n",(0,i.jsxs)(n.p,{children:["This is achieved through a proxy service called the ",(0,i.jsx)(n.code,{children:"edge-endpoint"}),", a lightweight, open-source service that runs on your edge devices. The ",(0,i.jsx)(n.code,{children:"edge-endpoint"})," is responsible for downloading and running models and communicating with the Groundlight cloud service. You can find the source code and documentation for the ",(0,i.jsx)(n.code,{children:"edge-endpoint"})," ",(0,i.jsx)(n.a,{href:"https://github.com/groundlight/edge-endpoint",children:"on GitHub"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"how-the-edge-endpoint-works",children:"How the Edge Endpoint Works"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"edge-endpoint"})," is a ",(0,i.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Proxy_server",children:"proxy service"})," that runs on your edge devices. It intercepts requests and responses between your application and the Groundlight cloud service, enabling you to run Groundlight's ML models locally on your edge devices."]}),"\n",(0,i.jsxs)(n.p,{children:["When your application sends an image query to the Groundlight cloud service, the ",(0,i.jsx)(n.code,{children:"edge-endpoint"})," intercepts the request and downloads the relevant edge-sized model from the cloud. It then runs the model locally on the edge device and returns the result to your application. By default, it will return answers without escalating to the cloud if the edge model answers above the specified confidence threshold. Otherwise, it will escalate to the cloud for a more confident answer. This process also allows Groundlight to learn from examples that are challenging for the edge model. Once a new edge model is trained to handle such examples, it will automatically be downloaded to the edge device for future queries."]}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"edge-endpoint"})," operates as a set of ",(0,i.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Containerization_(computing)",children:"containers"}),' on an "edge device," which can be an NVIDIA Jetson device, a rack-mounted server, or even a Raspberry Pi. The main container is the ',(0,i.jsx)(n.code,{children:"edge-endpoint"})," proxy service, which handles requests and manages other containers, such as the ",(0,i.jsx)(n.code,{children:"inferencemodel"})," containers responsible for loading and running the ML models."]}),"\n",(0,i.jsx)(n.h2,{id:"installing-and-running-the-edge-endpoint",children:"Installing and Running the Edge Endpoint"}),"\n",(0,i.jsxs)(n.p,{children:["To set up an ",(0,i.jsx)(n.code,{children:"edge-endpoint"})," manually, please refer to ",(0,i.jsx)(n.a,{href:"https://github.com/groundlight/edge-endpoint/blob/main/deploy/README.md",children:"the deploy README"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["Groundlight also provides managed ",(0,i.jsx)(n.code,{children:"edge-endpoint"})," servers. Management is performed via ",(0,i.jsx)(n.a,{href:"https://www.balena.io/",children:"Balena"}),". To received a managed ",(0,i.jsx)(n.code,{children:"edge-endpoint"}),", please ",(0,i.jsx)(n.a,{href:"mailto:info@groundlight.ai",children:"contact us"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"using-the-edge-endpoint",children:"Using the Edge Endpoint"}),"\n",(0,i.jsxs)(n.p,{children:["To utilize the ",(0,i.jsx)(n.code,{children:"edge-endpoint"}),", set the Groundlight SDK to use the ",(0,i.jsx)(n.code,{children:"edge-endpoint"}),"'s URL instead of the cloud endpoint. Your application logic can remain unchanged and will work seamlessly with the Groundlight ",(0,i.jsx)(n.code,{children:"edge-endpoint"}),". This setup allows some ML responses to be returned much faster, locally."]}),"\n",(0,i.jsxs)(n.p,{children:["Note that image queries processed at the ",(0,i.jsx)(n.code,{children:"edge-endpoint"})," will not appear on the Groundlight cloud dashboard unless specifically configured. In such cases, the edge prediction will not be reflected in the cloud image query. Additional documentation and configuration options are available in the ",(0,i.jsx)(n.a,{href:"https://github.com/groundlight/edge-endpoint#running-the-edge-endpoint",children:"edge-endpoint repository"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["To set the Groundlight Python SDK to submit requests to your ",(0,i.jsx)(n.code,{children:"edge-endpoint"})," proxy server, you can either pass the endpoint URL to the Groundlight constructor like this:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:"notest",children:'from groundlight import Groundlight\ngl = Groundlight(endpoint="http://localhost:30101")\n'})}),"\n",(0,i.jsxs)(n.p,{children:["or set the ",(0,i.jsx)(n.code,{children:"GROUNDLIGHT_ENDPOINT"})," environment variable like:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"export GROUNDLIGHT_ENDPOINT=http://localhost:30101\npython your_app.py\n"})}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.p,{children:["In the above example, the ",(0,i.jsx)(n.code,{children:"edge-endpoint"})," is running on the same machine as the application, so the endpoint URL is ",(0,i.jsx)(n.code,{children:"http://localhost:30101"}),". If the ",(0,i.jsx)(n.code,{children:"edge-endpoint"})," is running on a different machine, you should replace ",(0,i.jsx)(n.code,{children:"localhost"})," with the IP address or hostname of the machine running the ",(0,i.jsx)(n.code,{children:"edge-endpoint"}),"."]})}),"\n",(0,i.jsx)(n.h2,{id:"edge-endpoint-performance",children:"Edge Endpoint performance"}),"\n",(0,i.jsxs)(n.p,{children:["We have benchmarked the ",(0,i.jsx)(n.code,{children:"edge-endpoint"})," handling 500 requests/sec at a latency of less than 50ms on an off-the-shelf ",(0,i.jsx)(n.a,{href:"https://us.msi.com/Laptop/Katana-15-B13VX/Specification",children:"Katana 15 B13VGK-1007US"})," laptop (Intel\xae Core\u2122 i9-13900H CPU, NVIDIA\xae GeForce RTX\u2122 4070 Laptop GPU, 32GB DDR5 5200MHz RAM) running Ubuntu 20.04."]}),"\n",(0,i.jsxs)(n.p,{children:["The following graphs show the throughput and latency of the ",(0,i.jsx)(n.code,{children:"edge-endpoint"})," running on the Katana 15 laptop. As time progresses along the x-axis, the benchmark script ramps up the number of requests per second from 1 to 500 (and the number of clients submitting requests from 1 to 60). The y-axes shows the throughput in requests per second and the latency in seconds."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"edge-endpoint throughput",src:t(5545).A+"",width:"800",height:"600"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"edge-endpoint latency",src:t(8961).A+"",width:"800",height:"600"})}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"edge-endpoint"})," is designed to be lightweight and efficient, and can be run on a variety of edge devices, including NVIDIA Jetson devices, Raspberry Pi, and other ARM- and x86-based devices."]})]})}function l(e={}){const{wrapper:n}={...(0,d.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},8961:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/edge-endpoint-latency-249758baccfe7f919509e0a0ae1faa5e.png"},5545:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/edge-endpoint-throughput-828334feb85187776d4a2c7f7f41057a.png"},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>r});var o=t(6540);const i={},d=o.createContext(i);function s(e){const n=o.useContext(d);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),o.createElement(d.Provider,{value:n},e.children)}}}]);