"use strict";(self.webpackChunkweb=self.webpackChunkweb||[]).push([[4935],{1625:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"introducing-framegrab","metadata":{"permalink":"/python-sdk/blog/introducing-framegrab","source":"@site/blog/2023-12-06-framegrab.md","title":"Introducing Groundlight\'s FrameGrab Library","description":"We would like to introduce you to the FrameGrab library.","date":"2023-12-06T00:00:00.000Z","formattedDate":"December 6, 2023","tags":[{"label":"groundlight-extensions","permalink":"/python-sdk/blog/tags/groundlight-extensions"},{"label":"framegrab","permalink":"/python-sdk/blog/tags/framegrab"}],"readingTime":3.12,"hasTruncateMarker":true,"authors":[{"name":"Tim Huff","title":"Engineering intern at Groundlight","image_url":"https://a-us.storyblok.com/f/1015187/1000x1000/06b25bf1a6/hufft.jpg","imageURL":"https://a-us.storyblok.com/f/1015187/1000x1000/06b25bf1a6/hufft.jpg"},{"name":"Blaise Munyampirwa","title":"Engineer at Groundlight","image_url":"https://a-us.storyblok.com/f/1015187/1000x1000/d12109465d/munyampirwab.jpg","imageURL":"https://a-us.storyblok.com/f/1015187/1000x1000/d12109465d/munyampirwab.jpg"},{"name":"Leo Dirac","title":"CTO and Co-founder at Groundlight","image_url":"https://a-us.storyblok.com/f/1015187/284x281/602a9c95c5/diracl.png","imageURL":"https://a-us.storyblok.com/f/1015187/284x281/602a9c95c5/diracl.png"},{"name":"Tyler Romero","title":"Senior Machine Learning Engineer","image_url":"https://a-us.storyblok.com/f/1015187/1000x1000/368053d79a/romerot.jpg","imageURL":"https://a-us.storyblok.com/f/1015187/1000x1000/368053d79a/romerot.jpg"},{"name":"Michael Vogelsong","title":"Chief ML Scientist","image_url":"https://a-us.storyblok.com/f/1015187/1000x1000/c87b9d30f4/vogelsongm.jpg","imageURL":"https://a-us.storyblok.com/f/1015187/1000x1000/c87b9d30f4/vogelsongm.jpg"}],"frontMatter":{"title":"Introducing Groundlight\'s FrameGrab Library","description":"We would like to introduce you to the FrameGrab library.","slug":"introducing-framegrab","authors":[{"name":"Tim Huff","title":"Engineering intern at Groundlight","image_url":"https://a-us.storyblok.com/f/1015187/1000x1000/06b25bf1a6/hufft.jpg","imageURL":"https://a-us.storyblok.com/f/1015187/1000x1000/06b25bf1a6/hufft.jpg"},{"name":"Blaise Munyampirwa","title":"Engineer at Groundlight","image_url":"https://a-us.storyblok.com/f/1015187/1000x1000/d12109465d/munyampirwab.jpg","imageURL":"https://a-us.storyblok.com/f/1015187/1000x1000/d12109465d/munyampirwab.jpg"},{"name":"Leo Dirac","title":"CTO and Co-founder at Groundlight","image_url":"https://a-us.storyblok.com/f/1015187/284x281/602a9c95c5/diracl.png","imageURL":"https://a-us.storyblok.com/f/1015187/284x281/602a9c95c5/diracl.png"},{"name":"Tyler Romero","title":"Senior Machine Learning Engineer","image_url":"https://a-us.storyblok.com/f/1015187/1000x1000/368053d79a/romerot.jpg","imageURL":"https://a-us.storyblok.com/f/1015187/1000x1000/368053d79a/romerot.jpg"},{"name":"Michael Vogelsong","title":"Chief ML Scientist","image_url":"https://a-us.storyblok.com/f/1015187/1000x1000/c87b9d30f4/vogelsongm.jpg","imageURL":"https://a-us.storyblok.com/f/1015187/1000x1000/c87b9d30f4/vogelsongm.jpg"}],"tags":["groundlight-extensions","framegrab"],"image":"https://i.imgur.com/mErPwqL.png","hide_table_of_contents":false},"unlisted":false},"content":"At Groundlight, we continue to build infrastructure that allows our customers to easily use computer \\nvision without a pre-existing dataset for industrial inspection, retail analytics, mobile robotics, and \\nmuch more. We\'ve built many features towards the goal of declarative computer vision, and today we are excited to \\nintroduce FrameGrab, a Python library designed to make it easy to grab frames from\\ncameras or streams. \\n\\nFrameGrab supports generic USB cameras, RTSP streams, Basler USB cameras, Basler GigE cameras, and Intel RealSense depth cameras. \\n\\n\x3c!-- truncate --\x3e\\n\\n\\n## Grabbing Camera Frames\\n\\nFrame grabber objects are configured through YAML. The configuration combines the camera type, camera ID, and the camera\\noptions. The YAML config contains many configurable features, but only `input_type` is required. Valid choices for \\n`input_type` include \\n\\n* generic_usb\\n* rtsp\\n* realsense\\n* basler \\n\\nHere is an example of how to use the generic USB configuration \\n\\n```python notest\\nfrom framegrab import FrameGrabber \\n\\nconfig = \\"\\"\\"\\nname: Front Door Camera\\ninput_type: generic_usb\\nid:\\n  serial_number: 23432570\\noptions:\\n    resolution:\\n        height: 1080\\n        width: 1920\\n    zoom:\\n        digital: 1.5\\n\\"\\"\\"\\n\\ngrabber = FrameGrabber.create_grabber_yaml(config)\\nframe = grabber.grab()\\n\\n# Do real work with the frame \\n\\n# Finally release the grabber object \\ngrabber.release()\\n\\n```\\n\\nFor the full set of configurable parameters, please refer to the [FrameGrab repository](https://github.com/groundlight/framegrab/tree/main).\\n\\n## Multi-cam Configuration \\n\\nIf you have multiple cameras of the same type plugged in, we recommend you include serial numbers in the YAML config to \\nensure proper pairing. The default pairing behavior is sequential (i.e., configurations will be paired with cameras in \\na sequential ordering). \\n\\nYou can add serial numbers for multiple cameras like this\\n\\n```yaml \\nGL_CAMERAS: |\\n  - name: on robot arm\\n    input_type: realsense\\n    options: \\n      depth:\\n        side_by_side: 1\\n      crop:\\n        relative:\\n          right: .8\\n  - name: conference room\\n      input_type: rtsp\\n      id: \\n        rtsp_url: rtsp://admin:password@192.168.1.20/cam/realmonitor?channel=1&subtype=0\\n      options:\\n        crop:\\n          pixels:\\n            top: 350\\n            bottom: 1100\\n            left: 1100\\n            right: 2000\\n  - name: workshop\\n    input_type: generic_usb\\n    id:\\n      serial_number: B77D3A8F\\n\\n```\\n\\n## FrameGrab Autodiscovery Mode \\n\\nAmong other features, FrameGrab also includes autodiscovery mode. This allows you to automatically connect to all cameras \\nthat are plugged into your machine (or discoverable on the network). Autodiscovery will load up default configurations \\nfor each camera. \\n\\n:::note\\n\\nPlease note that RTSP streams cannot be autodiscovered in this manner. RTSP URLs must be pre-specified in the \\nconfigurations. \\n\\n:::\\n\\nWe recommend autodiscovery for simple applications where you don\'t need to set any special options on your cameras. \\nIt is also a convenient method for finding the serial numbers of your cameras in case they are not printed on them. \\n\\nBelow is a short example of how to launch autodiscovery mode. \\n\\n```python notest\\nfrom framegrab import FrameGrabber\\n\\ngrabbers = FrameGrabber.autodiscover()\\n\\n# Print some information about the discovered cameras\\nfor grabber in grabbers.values():\\n    print(grabber.config)\\n\\n    # Do real work \\n\\n    # Release the frame grabber object \\n    grabber.release()\\n\\n```\\n\\n\\n## Using FrameGrab for Motion Detection \\n\\nWith this release, we also continue to support [motion detection](https://en.wikipedia.org/wiki/Motion_detection) via frame differencing, a \\nfast algorithm for easily detecting motion in a sequence of frames. \\n\\nTo use motion detection, initialize the MotionDetector instance with the desired percentage of pixels \\nneeded to change in an image for it to be flagged for motion and the minimum brightness change for each pixel for it \\nto be considered changed. Here is a comprehensive example. \\n\\n```python notest\\nfrom framegrab import FrameGrabber, MotionDetector\\n\\nconfig = {\\n    \'input_type\': \'webcam\',\\n}\\ngrabber = FrameGrabber.create_grabber(config)\\nmotion_detector = MotionDetector(pct_threshold=motion_threshold, val_threshold=60)\\n\\nwhile True:\\n    frame = grabber.grab()\\n    if frame is None:\\n        print(\\"No frame captured!\\")\\n        continue\\n\\n    if motion_detector.motion_detected(frame):\\n        print(\\"Motion detected!\\")\\n\\n```\\n\\n\\n## Conclusion \\n\\nRecent releases of FrameGrab add various easy to use features. We now support \\nmultiple camera types and continue to support motion detection. \\n\\nIf you encounter any issues while using FrameGrab, please feel free to file an issue in our [GitHub repository](https://github.com/groundlight/framegrab)\\nand while there, review guidelines for [contributing](https://github.com/groundlight/framegrab#contributing) to this library."}]}')}}]);